{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algerian Forest Fires Dataset\n",
    "Data Set Information:\n",
    "\n",
    "The dataset includes 244 instances that regroup a data of two regions of Algeria,namely the Bejaia region located in the northeast of Algeria and the Sidi Bel-abbes region located in the northwest of Algeria.\n",
    "\n",
    "122 instances for each region.\n",
    "\n",
    "The period from June 2012 to September 2012. The dataset includes 11 attribues and 1 output attribue (class) The 244 instances have been classified into fire(138 classes) and not fire (106 classes) classes.\n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "Date : (DD/MM/YYYY) Day, month ('june' to 'september'), year (2012) Weather data observations\n",
    "\n",
    "Temp : temperature noon (temperature max) in Celsius degrees: 22 to 42\n",
    "\n",
    "RH : Relative Humidity in %: 21 to 90\n",
    "\n",
    "Ws :Wind speed in km/h: 6 to 29\n",
    "\n",
    "Rain: total day in mm: 0 to 16.8 FWI Components\n",
    "\n",
    "Fine Fuel Moisture Code (FFMC) index from the FWI system: 28.6 to 92.5\n",
    "\n",
    "Duff Moisture Code (DMC) index from the FWI system: 1.1 to 65.9\n",
    "\n",
    "Drought Code (DC) index from the FWI system: 7 to 220.4\n",
    "\n",
    "Initial Spread Index (ISI) index from the FWI system: 0 to 18.5\n",
    "\n",
    "Buildup Index (BUI) index from the FWI system: 1.1 to 68\n",
    "\n",
    "Fire Weather Index (FWI) Index: 0 to 31.1\n",
    "\n",
    "Classes: two classes, namely Fire and not Fire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing all the necessary libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading the original data\n",
    "df = pd.read_csv('Algerian_forest_fires_dataset.csv',header=1) # header=1 removes Bejaia Region Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## information about the dataset\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## missing values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is converted into two sets based on Region from 122th index, we can make a new column based on the Region\n",
    "\n",
    "1 : \"Bejaia Region Dataset\"\n",
    "\n",
    "2 : \"Sidi-Bel Abbes Region Dataset\"\n",
    "\n",
    "Add new column with region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:122,\"Region\"]=0\n",
    "df.loc[122:,\"Region\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## data type conversion to int \n",
    "df['Region']=df['Region'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  checking where is null\n",
    "df[df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##removing the null\n",
    "df=df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## now is there is any null now\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## in dataset in one row there is only column names\n",
    "df.iloc[[122]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove the 122th index \n",
    "df = df.drop(122).reset_index(drop=True)\n",
    "df.iloc[[122]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## to remove the space in columns\n",
    "df.columns=df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert the required columns data type from object to int\n",
    "df[['day', 'month', 'year', 'Temperature', 'RH']]=df[['day', 'month', 'year', 'Temperature', 'RH']].astype('int')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## changing the datatype of other cols as float except Classes\n",
    "others =[col for col in df.columns if df[col].dtype=='O']\n",
    "print('features having Object datatype are ', others)\n",
    "\n",
    "for i in others : \n",
    "    if i!='Classes':\n",
    "        df[i]=df[i].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets save this cleaned data into csv \n",
    "df.to_csv('Algerian_forest_fires_cleaned_dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop day , month , year \n",
    "dff = df.drop(['day','month','year'], axis=1)\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Classes']=df['Classes']\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff['Classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## encoding into binary of feature \"Classes\"\n",
    "dff['Classes']= np.where(dff['Classes'].str.contains('not fire'),0,1)\n",
    "dff['Classes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## density for all features \n",
    "plt.style.use('classic')  ## ggplot , seaborn \n",
    "dff.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## percentage of classes label \n",
    "percent = dff['Classes'].value_counts(normalize=True)*100\n",
    "percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## its pie chart \n",
    "labels= ['fire','not fire']\n",
    "plt.figure(figsize=(15,7))\n",
    "plt.pie(percent,labels=labels,autopct='%1.1F%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## correlation \n",
    "dff.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## heatmap\n",
    "plt.figure(figsize=(12, 12))  # Adjust the figure size\n",
    "sns.heatmap(dff.corr(), annot=True, cmap='coolwarm')  # Add a colormap for better visualization\n",
    "plt.title(\"Correlation Heatmap\")  # Optional: Add a title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## boxplot \n",
    "sns.boxplot(df['FWI'],color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## monthly analsis of fire \n",
    "df['Classes']=np.where(df['Classes'].str.contains('not fire'),'not fire','fire')\n",
    "dftemp=df[df['Region']==1]\n",
    "plt.plot(figsize=(13,7))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(data=dftemp,x='month',hue='Classes')\n",
    "plt.ylabel('Number of Fires',weight='bold')\n",
    "plt.xlabel('Months',weight='bold')\n",
    "plt.title(\"Fire Analysis of Sidi- Bel Regions\",weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Monthly Fire Analysis\n",
    "dftemp=df.loc[df['Region']==0]\n",
    "plt.plot(figsize=(13,6))\n",
    "sns.set_style('whitegrid')\n",
    "sns.countplot(x='month',hue='Classes',data=dftemp)\n",
    "plt.ylabel('Number of Fires',weight='bold')\n",
    "plt.xlabel('Months',weight='bold')\n",
    "plt.title(\"Fire Analysis of Brjaia Regions\",weight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Its observed that August and September had the most number of forest fires for both regions. And from the above plot of months, we can understand few things\n",
    "\n",
    "Most of the fires happened in August and very high Fires happened in only 3 months - June, July and August.\n",
    "\n",
    "Less Fires was on September"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## independent and dependent features \n",
    "X= dff.loc[: , dff.columns != 'FWI']\n",
    "y = dff['FWI']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,random_state=42,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## feature selection based on correlation \n",
    "X_train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check for multicollinearity \n",
    "corr = X_train.corr()\n",
    "plt.plot(figsize=(15,10))\n",
    "sns.heatmap(corr , annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(dataset , threshold): \n",
    "    corr_cols = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                corr_cols.add(colname)\n",
    "\n",
    "    return corr_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## threshold is set by domain expert \n",
    "dropping_features=correlation(X_train,0.85)\n",
    "dropping_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop the features when correlation is more than 85%\n",
    "X_train.drop(dropping_features , axis=1 , inplace=True)\n",
    "X_test.drop(dropping_features , axis=1 , inplace=True)\n",
    "X_train.shape , X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## standardisation of features / Z score \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled= scaler.fit_transform(X_train)\n",
    "X_test_scaled=scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## box plot to understand the effect of standard scaler \n",
    "plt.subplots(figsize=(25,10))\n",
    "plt.subplot(1,2,1)\n",
    "sns.boxplot(X_train)\n",
    "plt.title('data before scaling')\n",
    "plt.subplot(1,2,2)\n",
    "sns.boxplot(X_train_scaled)\n",
    "plt.title('data after scaling')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "LinReg = LinearRegression()\n",
    "LinReg.fit(X_train_scaled,y_train)\n",
    "y_pred = LinReg.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "LassoReg = Lasso()\n",
    "LassoReg.fit(X_train_scaled,y_train)\n",
    "y_pred = LassoReg.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "ridge = Ridge()\n",
    "ridge.fit(X_train_scaled,y_train)\n",
    "y_pred =ridge.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "elastic = ElasticNet()\n",
    "elastic.fit(X_train_scaled,y_train)\n",
    "y_pred = elastic.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "plt.scatter(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertunning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "lassocv = LassoCV(cv=5)\n",
    "lassocv.fit(X_train_scaled,y_train)\n",
    "y_pred = lassocv.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "print('selected alpha value ', lassocv.alpha_)\n",
    "msepath = lassocv.mse_path_\n",
    "alphas = lassocv.alphas_\n",
    "print(msepath.shape)\n",
    "print(alphas.shape)\n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RidgeCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "ridgecv = RidgeCV(cv=5)\n",
    "ridgecv.fit(X_train_scaled,y_train)\n",
    "y_pred = ridgecv.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "print(ridgecv.alpha_)\n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.metrics import mean_absolute_error , r2_score\n",
    "elastic_cv = ElasticNetCV(cv=5)\n",
    "elastic_cv.fit(X_train_scaled,y_train)\n",
    "y_pred = elastic_cv.predict(X_test_scaled)\n",
    "mae = mean_absolute_error(y_test,y_pred)\n",
    "score = r2_score(y_test,y_pred)\n",
    "print('mean score error is ',mae)\n",
    "print('r2 score is ',score)\n",
    "print(elastic_cv.alpha_)\n",
    "plt.scatter(y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickle is a Python module used for serializing and deserializing objects. Serialization is the process of converting a Python object (e.g., a trained machine learning model) into a byte stream that can be saved to a file or transferred over a network. Deserialization is the reverse processâ€”loading the object back into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pickle the ml model and pre processing model scaler\n",
    "import pickle\n",
    "pickle.dump(scaler,open('scaler.pkl','wb'))\n",
    "pickle.dump(ridge,open('ridge.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
